{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Data Project Presentation CODE1161 \n",
    "Name: Zhang Wang  (z5248079)\n",
    "\n",
    "Topic: Crash Data in Queensland, Australia"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "\"Damage Cost Analysis\" is a method of conducting economic analysis on the damages caused by accidents, disasters, or other events. This analysis aims to estimate the losses incurred by the event, including direct economic losses, indirect economic impacts, and other related costs. The purpose of this analysis is to help decision-makers understand the potential consequences of the event, providing a basis for policy-making, taking actions, or making investment decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gp\n",
    "import shapely\n",
    "import fiona\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from matplotlib.colors import ListedColormap\n",
    "file_name = \"/workspaces/dateproject/crashdate.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "penalty_data = pd.read_csv('/workspaces/dateproject/crashdate.csv')\n",
    "penalty_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Define valid ranges for longitude and latitude\n",
    "valid_longitude_range = (130, 160)\n",
    "valid_latitude_range = (-30, 0)\n",
    "\n",
    "# Filter the penalty_data based on valid longitude and latitude ranges\n",
    "filtered_data = penalty_data[\n",
    "    (penalty_data['Crash_Longitude'] >= valid_longitude_range[0]) &\n",
    "    (penalty_data['Crash_Longitude'] <= valid_longitude_range[1]) &\n",
    "    (penalty_data['Crash_Latitude'] >= valid_latitude_range[0]) &\n",
    "    (penalty_data['Crash_Latitude'] <= valid_latitude_range[1])\n",
    "]\n",
    "\n",
    "# Read the Queensland geospatial data\n",
    "queensland = gp.read_file(\n",
    "    '/workspaces/dateproject/date/queensland.json'\n",
    ")\n",
    "\n",
    "# Create a GeoDataFrame with filtered data points\n",
    "filtered_points = gp.GeoDataFrame(geometry=gp.points_from_xy(\n",
    "    filtered_data['Crash_Longitude'], filtered_data['Crash_Latitude']\n",
    "))\n",
    "\n",
    "# Create a plot showing the Queensland boundary and the filtered data points\n",
    "fig, axs = plt.subplots(figsize=(20, 10))\n",
    "queensland.boundary.plot(ax=axs, color='black', linewidth=1)  # Plot Queensland boundary\n",
    "filtered_points.plot(ax=axs, marker='o', markersize=2,\n",
    "                     alpha=0.5, color='mediumpurple', zorder=2)  # Plot filtered data points\n",
    "axs.set_title('Map of Filtered Crash Data in Queensland')\n",
    "axs.set_xlabel('Longitude')\n",
    "axs.set_ylabel('Latitude')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the geospatial data for localities from the specified shapefile\n",
    "burbs = gp.GeoDataFrame.from_file(\n",
    "    '/workspaces/dateproject/date/GDA2020/qld_localities.shp'\n",
    ")\n",
    "\n",
    "# Set the Coordinate Reference System (CRS) for the geospatial data\n",
    "# This ensures that the spatial information is interpreted correctly\n",
    "# The specified EPSG code (5234) represents GDA2020\n",
    "burbs.set_crs(epsg=5234, inplace=True, allow_override=True)\n",
    "\n",
    "# Select the locality data for Acacia Ridge from the loaded geospatial data\n",
    "gold_coast = burbs[burbs['LOC_NAME'].str.contains('Acacia Ridge', case=False)]\n",
    "\n",
    "# Plot the selected Acacia Ridge area boundary\n",
    "gold_coast.plot()\n",
    "\n",
    "# Set the plot title and labels for the x and y axes\n",
    "plt.title('Acacia Ridge Area Boundary')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Display the first 3 rows of the loaded geospatial data (localities)\n",
    "burbs.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function that calculates the centroid of a geometry\n",
    "def add_centroid(row):\n",
    "    return row.geometry.centroid\n",
    "\n",
    "# Apply the \"add_centroid\" function to each row in the GeoDataFrame \"burbs\"\n",
    "# along the specified axis (axis=1 indicates applying the function to rows)\n",
    "# The result is stored in a new column called \"centroid\"\n",
    "burbs[\"centroid\"] = burbs.apply(add_centroid, axis=1)\n",
    "\n",
    "# Sample two random rows from the GeoDataFrame \"burbs\"\n",
    "# This provides a glimpse of the data after adding the \"centroid\" column\n",
    "burbs.sample(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the centroids of the localities in the GeoDataFrame \"burbs\"\n",
    "burbs.centroid.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the geometry (locality polygon) of the second row from the GeoDataFrame \"burbs\"\n",
    "a = burbs.iloc[1]\n",
    "\n",
    "# Calculate and print the centroid of the extracted geometry (locality polygon)\n",
    "print(a.centroid)\n",
    "\n",
    "# Plot the extracted geometry (locality polygon) centroid on the map\n",
    "a.centroid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Create a Shapely Point object representing the coordinates of a location\n",
    "right_here = shapely.geometry.point.Point(153.0587653330788, -27.478362304023605)\n",
    "\n",
    "# Calculate the distance from each locality centroid to the specified location (right_here)\n",
    "# The calculated distances are stored in a new column named \"distance_from_UNSW\"\n",
    "burbs[\"distance_from_The_selected_center_point\"] = burbs.centroid.distance(right_here)\n",
    "\n",
    "# Plot a histogram of the distribution of distances from UNSW for all localities\n",
    "# The \"bins\" parameter specifies the number of bins in the histogram\n",
    "burbs.distance_from_The_selected_center_point.hist(bins=200)\n",
    "\n",
    "# Set the title for the histogram plot\n",
    "plt.title(\"Distribution of distances from The selected center point\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select localities from the GeoDataFrame \"burbs\" that are within a certain distance (less than 0.03) from UNSW\n",
    "close_burbs = burbs[burbs.distance_from_The_selected_center_point < 0.022]\n",
    "\n",
    "# Plot the selected localities on the map\n",
    "close_burbs.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = list(zip(penalty_data['Crash_Longitude'], penalty_data['Crash_Latitude']))\n",
    "for point in points:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list of points from the latitude and longitude columns in the penalty_data DataFrame\n",
    "points = list(zip(penalty_data['Crash_Longitude'], penalty_data['Crash_Latitude']))\n",
    "\n",
    "# Iterate over each point in the list (currently just a placeholder pass)\n",
    "for point in points:\n",
    "    pass\n",
    "\n",
    "# Create another list of points from the latitude and longitude columns in the penalty_data DataFrame\n",
    "points = list(zip(penalty_data['Crash_Longitude'], penalty_data['Crash_Latitude']))\n",
    "\n",
    "# Iterate over each point in the list (currently just a placeholder pass)\n",
    "for point in points:\n",
    "    pass\n",
    "\n",
    "# Specify the column containing geometry information in the close_burbs GeoDataFrame\n",
    "polygon_column = 'geometry'\n",
    "\n",
    "# Extract the polygons from the specified geometry column\n",
    "polygons = close_burbs[polygon_column]\n",
    "\n",
    "# Convert the list of polygon coordinates to a list of Polygon objects\n",
    "polygonslist = [Polygon(coords) for coords in polygons]\n",
    "\n",
    "# Create a MultiPolygon object from the list of Polygon objects\n",
    "multi_polygon = MultiPolygon(polygonslist)\n",
    "\n",
    "# Find the points that are inside the MultiPolygon\n",
    "points_inside_polygons = [\n",
    "    point for point in points if multi_polygon.contains(Point(point))\n",
    "]\n",
    "\n",
    "# Create a plot to visualize the points inside the polygons\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot the close_burbs GeoDataFrame as a background\n",
    "close_burbs.plot(ax=ax, color='lightgray', edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Plot the points inside the polygons in blue\n",
    "for point in points_inside_polygons:\n",
    "    plt.plot(point[0], point[1], 'bo', markersize=3)\n",
    "\n",
    "# Set plot attributes\n",
    "ax.set_title('The location of the crash in the Specified boundary')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'Crash_Day_Of_Week' column as labels for crash days of the week\n",
    "crash_day_of_week_labels = penalty_data['Crash_Day_Of_Week']\n",
    "\n",
    "# Define a mapping from day of the week labels to numeric values\n",
    "day_of_week_mapping = {'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3, 'Friday': 4, 'Saturday': 5, 'Sunday': 6}\n",
    "\n",
    "# Map day of the week labels to numeric values\n",
    "crash_day_of_week_numeric = [day_of_week_mapping[label] for label in crash_day_of_week_labels]\n",
    "\n",
    "# Define colors for each day of the week\n",
    "colors = ['red', 'blue', 'green', 'purple', 'orange', 'black', 'pink']\n",
    "\n",
    "# Create a colormap for the days of the week\n",
    "cmap = ListedColormap(colors)\n",
    "\n",
    "# Define a color normalization range\n",
    "norm = plt.Normalize(vmin=0, vmax=len(day_of_week_mapping) - 1)\n",
    "\n",
    "# Create a ScalarMappable for the colormap and set it to the current color array\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "# Specify the column containing geometry information in the close_burbs GeoDataFrame\n",
    "polygon_column = 'geometry'\n",
    "\n",
    "# Extract the polygons from the specified geometry column\n",
    "polygons = close_burbs[polygon_column]\n",
    "\n",
    "# Convert the list of polygon coordinates to a list of Polygon objects\n",
    "polygonslist = [Polygon(coords) for coords in polygons]\n",
    "\n",
    "# Create a MultiPolygon object from the list of Polygon objects\n",
    "multi_polygon = MultiPolygon(polygonslist)\n",
    "\n",
    "# Find the points and their corresponding days of the week that are inside the MultiPolygon\n",
    "points_inside_polygons = [\n",
    "    (point, day) for point, day in zip(points, crash_day_of_week_numeric) if multi_polygon.contains(Point(point))\n",
    "]\n",
    "\n",
    "# Create a plot to visualize the points inside the polygons with day of the week colors\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot the close_burbs GeoDataFrame as a background\n",
    "close_burbs.plot(ax=ax, color='lightgray', edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Plot the points inside the polygons using different colors based on the day of the week\n",
    "for point, day in points_inside_polygons:\n",
    "    plt.plot(point[0], point[1], 'o', color=sm.to_rgba(day), markersize=5)\n",
    "\n",
    "# Create a colorbar to show the mapping between colors and days of the week\n",
    "cbar = plt.colorbar(sm, ax=ax, ticks=range(len(day_of_week_mapping)))\n",
    "cbar.set_ticklabels(day_of_week_mapping.keys())\n",
    "\n",
    "# Set plot attributes\n",
    "ax.set_title('The location of the crash in the Specified boundary(Day of Week)')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'Crash_Severity' column as labels for crash severity levels\n",
    "crash_severity_labels = penalty_data['Crash_Severity']\n",
    "\n",
    "# Define the labels for crash severity levels\n",
    "severity_labels = ['Hospitalisation', 'Property damage only', 'Minor injury', 'Medical treatment', 'Fatal']\n",
    "\n",
    "# Create a mapping from crash severity labels to numeric values\n",
    "severity_mapping = {label: index for index, label in enumerate(severity_labels)}\n",
    "\n",
    "# Map crash severity labels to numeric values using the defined mapping\n",
    "crash_severity_numeric = [severity_mapping[label] for label in crash_severity_labels]\n",
    "\n",
    "# Define colors for each crash severity level\n",
    "colors = ['red', 'blue', 'green', 'purple', 'black']\n",
    "\n",
    "# Create a colormap for the crash severity levels\n",
    "cmap = ListedColormap(colors)\n",
    "\n",
    "# Define a color normalization range\n",
    "norm = plt.Normalize(vmin=0, vmax=len(severity_labels) - 1)\n",
    "\n",
    "# Create a ScalarMappable for the colormap and set it to the current color array\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "# Specify the column containing geometry information in the close_burbs GeoDataFrame\n",
    "polygon_column = 'geometry'\n",
    "\n",
    "# Extract the polygons from the specified geometry column\n",
    "polygons = close_burbs[polygon_column]\n",
    "\n",
    "# Convert the list of polygon coordinates to a list of Polygon objects\n",
    "polygonslist = [Polygon(coords) for coords in polygons]\n",
    "\n",
    "# Create a MultiPolygon object from the list of Polygon objects\n",
    "multi_polygon = MultiPolygon(polygonslist)\n",
    "\n",
    "# Find the points and their corresponding crash severity levels that are inside the MultiPolygon\n",
    "points_inside_polygons = [\n",
    "    (point, severity) for point, severity in zip(points, crash_severity_numeric) if multi_polygon.contains(Point(point))\n",
    "]\n",
    "\n",
    "# Create a plot to visualize the points inside the polygons with colors representing crash severity levels\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot the close_burbs GeoDataFrame as a background\n",
    "close_burbs.plot(ax=ax, color='lightgray', edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Plot the points inside the polygons using different colors based on crash severity levels\n",
    "for point, severity in points_inside_polygons:\n",
    "    plt.plot(point[0], point[1], 'o', color=sm.to_rgba(severity), markersize=5)\n",
    "\n",
    "# Create a colorbar to show the mapping between colors and crash severity levels\n",
    "cbar = plt.colorbar(sm, ax=ax, ticks=range(len(severity_labels)))\n",
    "cbar.set_ticklabels(severity_labels)\n",
    "\n",
    "# Set plot attributes\n",
    "ax.set_title('The location of the crash in the Specified boundary(Crash Severity)')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path to the CSV file containing the data\n",
    "file_path = '/workspaces/dateproject/crashdate.csv'\n",
    "\n",
    "# Read the data from the CSV file into a DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "# Convert the \"Crash_Day_Of_Week\" column to uppercase to ensure consistent casing\n",
    "data[\"Crash_Day_Of_Week\"] = data[\"Crash_Day_Of_Week\"].str.upper()\n",
    "\n",
    "# Define a mapping from day names to day numbers\n",
    "day_mapping = {\n",
    "    \"MONDAY\": 1,\n",
    "    \"TUESDAY\": 2,\n",
    "    \"WEDNESDAY\": 3,\n",
    "    \"THURSDAY\": 4,\n",
    "    \"FRIDAY\": 5,\n",
    "    \"SATURDAY\": 6,\n",
    "    \"SUNDAY\": 7\n",
    "}\n",
    "\n",
    "# Map day names to day numbers and create a new column \"Day_Number\" in the DataFrame\n",
    "data[\"Day_Number\"] = data[\"Crash_Day_Of_Week\"].map(day_mapping)\n",
    "\n",
    "# Group the data by \"Day_Number\" and count occurrences for each day\n",
    "day_counts = data.groupby(\"Day_Number\").size()\n",
    "\n",
    "# Reindex the day counts to ensure all days of the week are included, even if no data exists for a particular day\n",
    "day_counts = day_counts.reindex([1, 2, 3, 4, 5, 6, 7], fill_value=0)\n",
    "\n",
    "# Plot a bar chart to visualize the data counts for each day of the week\n",
    "day_counts.plot(kind=\"bar\", color=\"blue\")\n",
    "\n",
    "# Set the x-axis tick labels to display the day names\n",
    "plt.xticks(range(7), [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"], rotation=45)\n",
    "\n",
    "# Set the title, x-axis label, and y-axis label for the plot\n",
    "plt.title(\"Crash Counts by Day of the Week\")\n",
    "plt.xlabel(\"Day of the Week\")\n",
    "plt.ylabel(\"Crash Count\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path to the CSV file containing the data\n",
    "file_path = '/workspaces/dateproject/crashdate.csv'\n",
    "\n",
    "# Read the data from the CSV file into a DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Define a list of crash severity values to filter the data\n",
    "severity_values = ['Hospitalisation', 'Property damage only', 'Minor injury', 'Medical treatment', 'Fatal']\n",
    "\n",
    "# Filter the data to include only rows with crash severity values in the defined list\n",
    "filtered_data = data[data[\"Crash_Severity\"].isin(severity_values)]\n",
    "\n",
    "# Count the occurrences of each unique crash severity value in the filtered data\n",
    "severity_counts = filtered_data[\"Crash_Severity\"].value_counts()\n",
    "\n",
    "# Plot a bar chart to visualize the data counts for each crash severity value\n",
    "severity_counts.plot(kind='bar', color='blue')\n",
    "\n",
    "# Set the title, x-axis label, and y-axis label for the plot\n",
    "plt.title(\"Crash Counts by Crash Severity\")\n",
    "plt.xlabel(\"Crash Severity\")\n",
    "plt.ylabel(\"Crash Count\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cross-tabulation between 'Crash_Day_Of_Week' and 'Crash_Severity'\n",
    "cross_tab = pd.crosstab(data[\"Crash_Day_Of_Week\"], data[\"Crash_Severity\"])\n",
    "\n",
    "# Create a heatmap to visualize the cross-tabulation\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cross_tab, annot=True, cmap=\"YlGnBu\", fmt='d')\n",
    "plt.title(\"Heatmap of Day Of Week by Crash Severity\")\n",
    "plt.xlabel(\"Crash Severity\")\n",
    "plt.ylabel(\"Day Of Week\")\n",
    "plt.show()\n",
    "# Normalize the crosstab by row (Crash_Day_Of_Week) to get percentages\n",
    "cross_tab_percent = cross_tab.div(cross_tab.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Create a heatmap of the normalized crosstab (percentages)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cross_tab_percent, annot=True, cmap=\"YlGnBu\", fmt='.2f')\n",
    "plt.title(\"Heatmap of Day Of Week by Crash Severity (Percentages)\")\n",
    "plt.xlabel(\"Crash Severity\")\n",
    "plt.ylabel(\"Day Of Week\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Initialize a LabelEncoder for encoding categorical variables\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Encode the 'Crash_Speed_Limit' and 'Crash_Severity' columns and add them as new encoded columns\n",
    "data['Crash_Speed_Limit_Encoded'] = encoder.fit_transform(data['Crash_Speed_Limit'])\n",
    "data['Crash_Severity_Encoded'] = encoder.fit_transform(data['Crash_Severity'])\n",
    "\n",
    "# Calculate the correlation between the encoded 'Crash_Speed_Limit' and 'Crash_Severity' columns\n",
    "correlation = data['Crash_Speed_Limit_Encoded'].corr(data['Crash_Severity_Encoded'])\n",
    "\n",
    "# Create a cross-tabulation between 'Crash_Speed_Limit' and 'Crash_Severity' columns\n",
    "cross_tab = pd.crosstab(data['Crash_Speed_Limit'], data['Crash_Severity'])\n",
    "\n",
    "# Create a heatmap to visualize the cross-tabulation\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cross_tab, annot=True, cmap=sns.color_palette(\"YlGnBu\", n_colors=300), fmt='d')\n",
    "plt.title(\"Heatmap of Speed Limit by Crash Severity\")\n",
    "plt.xlabel(\"Crash Severity\")\n",
    "plt.ylabel(\"Speed Limit\")\n",
    "plt.show()\n",
    "\n",
    "# Create another cross-tabulation between 'Crash_Lighting_Condition' and 'Crash_Severity' columns\n",
    "cross_tab = pd.crosstab(data[\"Crash_Lighting_Condition\"], data[\"Crash_Severity\"])\n",
    "\n",
    "# Create a heatmap to visualize the cross-tabulation\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cross_tab, annot=True, cmap=\"YlGnBu\", fmt='d')\n",
    "plt.title(\"Heatmap of Lighting Condition by Crash Severity\")\n",
    "plt.xlabel(\"Crash Severity\")\n",
    "plt.ylabel(\"Lighting Condition\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom order for the speed limit categories\n",
    "speed_limit_order = [\"0 - 50 km/h\", \"60 km/h\", \"70 km/h\", \"80 - 90 km/h\", \"100 - 110 km/h\"]\n",
    "\n",
    "# Create a cross-tabulation between 'Crash_Speed_Limit' and 'Crash_Severity'\n",
    "cross_tab = pd.crosstab(data[\"Crash_Speed_Limit\"], data[\"Crash_Severity\"])\n",
    "\n",
    "# Reorder the cross-tabulation based on the custom speed limit order\n",
    "cross_tab_reordered = cross_tab.reindex(speed_limit_order)\n",
    "\n",
    "# Calculate percentages within each row (speed limit category) to create a percentage heatmap\n",
    "cross_tab_percentage = cross_tab_reordered.div(cross_tab_reordered.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Create a heatmap to visualize the percentage cross-tabulation\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cross_tab_percentage, annot=True, cmap=\"YlGnBu\", fmt=\".2f\")\n",
    "plt.title(\"Heatmap of Speed Limit by Crash Severity (Percentage)\")\n",
    "plt.xlabel(\"Crash Severity\")\n",
    "plt.ylabel(\"Speed Limit\")\n",
    "plt.show()\n",
    "\n",
    "# Create another cross-tabulation between 'Crash_Lighting_Condition' and 'Crash_Severity'\n",
    "cross_tab = pd.crosstab(data[\"Crash_Lighting_Condition\"], data[\"Crash_Severity\"])\n",
    "\n",
    "# Calculate percentages within each row (lighting condition category) to create a percentage heatmap\n",
    "cross_tab_percentage = cross_tab.div(cross_tab.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Create a heatmap to visualize the percentage cross-tabulation\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cross_tab_percentage, annot=True, cmap=\"YlGnBu\", fmt='.2f')\n",
    "plt.title(\"Heatmap of Lighting Condition by Crash Severity (Percentage)\")\n",
    "plt.xlabel(\"Crash Severity\")\n",
    "plt.ylabel(\"Lighting Condition\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of columns of interest related to traffic units and casualty counts\n",
    "columns_of_interest = [\n",
    "    \"Count_Unit_Car\", \"Count_Unit_Motorcycle_Moped\", \"Count_Unit_Truck\",\n",
    "    \"Count_Unit_Bus\", \"Count_Unit_Bicycle\", \"Count_Unit_Pedestrian\",\n",
    "    \"Count_Unit_Other\",\n",
    "    \"Count_Casualty_Fatality\", \"Count_Casualty_Hospitalised\",\n",
    "    \"Count_Casualty_MedicallyTreated\", \"Count_Casualty_MinorInjury\"\n",
    "]\n",
    "\n",
    "# Subset the data to include only the columns of interest\n",
    "subset_data = data[columns_of_interest]\n",
    "\n",
    "# Calculate the correlation matrix between the selected columns\n",
    "correlation_matrix = subset_data.corr()\n",
    "\n",
    "# Create a heatmap to visualize the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"RdBu_r\", center=0)\n",
    "\n",
    "# Set the title for the heatmap\n",
    "plt.title(\"Correlation Heatmap between Means of transportation and Crash Severity\")\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "99px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "vscode": {
   "interpreter": {
    "hash": "cd1a4323fb379de9187160a9aa0337dabefd7009b5703fc03d0198e947213ff5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
